## Welcome to VULab: Visual Understanding Lab at CWRU! 👋 
Our research lab is dedicated to advancing visual understanding through cutting-edge AI and machine learning techniques. Our mission is to explore and develop innovative solutions in visual language models (VLMs), 3D vision, and more, to push the boundaries of how machines perceive and interpret the world.

## Amazing Projects in VULab
### Visual Language Models (VLMs)
[_Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions_](https://vulab-ai.github.io/YESBUT_Homepage/) [NeurIPS 2024 **Oral**]

### 3D Vision
[_View-consistent Object Removal in Radiance Fields_](https://vulab-ai.github.io/View-consistent_Object_Removal_in_Radiance_Fields/) [ACM MM 2024]
[_NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real Image Animation_](https://github.com/YuYin1/NeRFInvertor) [CVPR 2023]

<!--
### Generative Models
-->


Explore these projects and more to learn how we're shaping the future of visual AI!

## Lab members
- [ ] [Yu Yin](https://yin-yu.github.io/) (PI and Lab Director)
- [ ] [Yiren Lu](https://yiren-lu.com/) (Ph.D)
- [ ] [Disheng Liu]() (Ph.D)
- [ ] [Jerry Peng]() (Ph.D)
- [ ] [Tuo Liang](https://tuo-liang.github.io/) (MS)
- [ ] [Yunlai Zhou]() (MS)


<!--
**Here are some ideas to get you started:**

🙋‍♀️ A short introduction - what is your organization all about?
🌈 Contribution guidelines - how can the community get involved?
👩‍💻 Useful resources - where can the community find your docs? Is there anything else the community should know?
-->
