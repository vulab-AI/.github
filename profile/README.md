## Welcome to VULab: Visual Understanding Lab at CWRU! ðŸ‘‹ 
Our research lab is dedicated to advancing visual understanding through cutting-edge AI and machine learning techniques. Our mission is to explore and develop innovative solutions in visual language models (VLMs), 3D vision, and more, to push the boundaries of how machines perceive and interpret the world.

## Amazing Projects at VULab
### Large Foundation Models (LLMs, VLMs, VLAs)
- [Under-review] [\[Awesome-Spatial-VLMs\] _Spatial Intelligence in Vision-Language Models: A Comprehensive Survey_](https://github.com/vulab-AI/Awesome-Spatial-VLMs)
- [Under-review] [\[YesBut-v2\] _When â€˜YESâ€™ Meets â€˜BUTâ€™: Can AI Comprehend Contradictory Humor Through Comparative Reasoning?_](https://vulab-ai.github.io/YESBUT-v2/)
- [NeurIPS 2025] [_Praxis-VLM: Vision-Grounded Decision Making via Text-Driven Reinforcement Learning_](https://arxiv.org/pdf/2503.16965?)
- [NeurIPS 2024 **Oral**] [\[YesBut\] _Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions?_](https://vulab-ai.github.io/YESBUT_Homepage/) 
- [EMNLP 2024] [_VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values_](https://derekhu.com/project_page/viva_website_emnlp24/)
- [INLG 2024 **Oral**] [_AMERICANO: Argument Generation with Discourse-driven Decomposition and Multi-agent Interaction_](https://aclanthology.org/2024.inlg-main.8/)

Debate-to-Write: A Persona-Driven Multi-Agent Framework for Diverse Argument Generation
International Conference on Computational Linguistics (COLING), 2025
  
### 3D Vision
- [NeurIPS 2025] [_Segment-then-Splat: A Unified Approach for 3D Open-Vocabulary Segmentation based on Gaussian Splatting_](https://vulab-ai.github.io/Segment-then-Splat/)
- [Under-review] [_CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data_](https://arxiv.org/pdf/2503.04852)
- [CVPR 2025] [_BARD-GS: Blur-Aware Reconstruction of Dynamic Scenes via Gaussian Splatting_](https://vulab-ai.github.io/BARD-GS/)
- [ACM MM 2024] [_View-consistent Object Removal in Radiance Fields_](https://vulab-ai.github.io/View-consistent_Object_Removal_in_Radiance_Fields/)
- [CVPR 2023] [_NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real Image Animation_](https://github.com/YuYin1/NeRFInvertor) 

### Embodied AI
- [Under-review] [_NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?_](https://vulab-ai.github.io/NEBULA-Alpha/)


<!--
### Generative Models
[Under-review] [_XXX_]()
-->


Explore these projects and more to learn how we're shaping the future of visual AI!

## Lab members
- [Yu Yin](https://yin-yu.github.io/) (_PI and Lab Director_)
- [Yiren Lu](https://yiren-lu.com/) (Ph.D)
- Disheng Liu (Ph.D)
- Jerry Peng (Ph.D)
- [Tuo Liang](https://tuo-liang.github.io/) (Ph.D)
- Chaoda Song(Ph.D)
- Yanyan Zhang (Ph.D)
- Yunlai Zhou (MS)
- Yichen Duan (MS)


<!--
**Here are some ideas to get you started:**

ðŸ™‹â€â™€ï¸ A short introduction - what is your organization all about?
ðŸŒˆ Contribution guidelines - how can the community get involved?
ðŸ‘©â€ðŸ’» Useful resources - where can the community find your docs? Is there anything else the community should know?
-->
